# Questão 3

Apresente um estudo comparando os seguintes algoritmos de otimização:

- Gradiente Estocástico (SGM)
- AdaGrad
- RMSProp
- Adam

Estes métodos ou otimizadores são utilizados no processo de aprendizagem de redes neurais/deep learning.

Os algoritmos de otimização desempenham um papel crucial no
treinamento de redes neurais, ajustando seus parâmetros para minimizar a função de perda e, consequentemente, melhorar o desempenho do modelo. Um exemplo clássico é o Gradient Descent (GD), que utiliza o gradiente da função de custo para atualizar os pesos da rede em direção ao mínimo global. No entanto, o GD pode enfrentar dificuldades, como ficar preso em mínimos locais. Para superar essas limitações, surgiram variações e métodos mais avançados, como o SGD, o AdaGrad, o RMSProp e o Adam, que serão discutidos em detalhes a seguir.

## Gradiente Estocástico (SGM)

O Gradiente Estocástico (SGM) é uma variação do método de Gradiente Descendente, amplamente utilizado para otimização em aprendizado de máquina. No método do Gradiente Descendente (GD), a atualização dos pesos é realizada utilizando o gradiente calculado em relação a todo o conjunto de dados.

A fórmula de atualização é dada por:

$\theta(t+1) = \theta(t) - \eta \nabla L(\theta(t))$

Onde:

- $\theta(t)$ representa os parâmetros do modelo na iteração $t$.
- $\eta$ é a taxa de aprendizado.
- $\nabla L(\theta(t))$ é o gradiente da função de perda $L$ em relação aos parâmetros $\theta(t)$, calculado para todo o conjunto de dados.

Embora o GD seja eficaz para encontrar mínimos globais em funções convexas, ele pode ser computacionalmente caro em grandes conjuntos de dados, pois requer o cálculo do gradiente para todos os exemplos a cada iteração.

A melhoria introduzida pelo **Gradiente Estocástico (SGM)** está na redução do custo computacional por iteração. Em vez de calcular o gradiente para todo o conjunto de dados, o SGM utiliza apenas um exemplo ou um mini-batch, como mostrado anteriormente. Isso permite atualizações mais frequentes dos pesos, acelerando o processo de treinamento e tornando-o mais eficiente para grandes volumes de dados. Além disso, o ruído introduzido pelo SGM pode ajudar o modelo a escapar de mínimos locais, o que é uma vantagem em problemas não convexos.

A atualização dos pesos no SGM segue a fórmula:

$\theta(t+1) = \theta(t) - \eta \nabla L(\theta(t); x_i, y_i)$

Onde:

- $\theta(t)$ representa os parâmetros do modelo na iteração $t$.
- $\eta$ é a taxa de aprendizado.
- $\nabla L(\theta(t); x_i, y_i)$ é o gradiente da função de perda $L$ em relação aos parâmetros $\theta(t)$, calculado para o exemplo $(x_i, y_i)$.
- $(x_i, y_i)$ é um par de exemplo de entrada e saída do conjunto de dados.

Essa abordagem reduz o custo computacional por iteração, tornando o treinamento mais rápido, especialmente em grandes conjuntos de dados. No entanto, o SGM introduz ruído no cálculo do gradiente, o que pode levar a oscilações durante a convergência. Apesar disso, o ruído pode ajudar o modelo a escapar de mínimos locais, tornando-o útil em problemas complexos.

O Gradiente Estocástico é simples de implementar e serve como base para muitos algoritmos de otimização mais avançados, como **AdaGrad**, **RMSProp** e **Adam**.
