{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Visualiza\u00e7\u00e3o 2D com Autoencoder\n", "Neste notebook, vamos:\n", "1. Gerar 4 distribui\u00e7\u00f5es gaussianas de 8 dimens\u00f5es com m\u00e9dias distintas.\n", "2. Treinar uma rede **autoencoder** para reduzir essas 8 dimens\u00f5es para 2.\n", "3. Visualizar os dados codificados em 2D."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### \ud83d\udccc Introdu\u00e7\u00e3o\n", "Este exerc\u00edcio envolve o uso de redes neurais autoencoders para realizar redu\u00e7\u00e3o de dimensionalidade de dados. Vamos trabalhar com quatro distribui\u00e7\u00f5es gaussianas em um espa\u00e7o de 8 dimens\u00f5es, com m\u00e9dias distintas, e utilizaremos um autoencoder para reduzir essa dimensionalidade para duas dimens\u00f5es, facilitando a visualiza\u00e7\u00e3o dos dados. A seguir, temos as etapas e respostas para cada item do exerc\u00edcio."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### a) Defini\u00e7\u00e3o das Distribui\u00e7\u00f5es Gaussianas\n", "O exerc\u00edcio come\u00e7a com quatro distribui\u00e7\u00f5es gaussianas, cada uma com m\u00e9dia diferente em um espa\u00e7o de 8 dimens\u00f5es. As m\u00e9dias dessas distribui\u00e7\u00f5es s\u00e3o:\n", "\n", "1. **M\u00e9dia de $C_1$:** $\\mathbf{m}_1 = (0, 0, 0, 0, 0, 0, 0, 0)$\n", "2. **M\u00e9dia de $C_2$:** $\\mathbf{m}_2 = (4, 0, 0, 0, 0, 0, 0, 0)$\n", "3. **M\u00e9dia de $C_3$:** $\\mathbf{m}_3 = (0, 0, 4, 0, 0, 0, 0, 0)$\n", "4. **M\u00e9dia de $C_4$:** $\\mathbf{m}_4 = (0, 0, 0, 0, 0, 0, 0, 4)$\n", "\n", "Cada distribui\u00e7\u00e3o tem vari\u00e2ncia unit\u00e1ria e suas amostras s\u00e3o geradas com base nessas m\u00e9dias."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### b) Utilizando o Autoencoder para Visualiza\u00e7\u00e3o\n", "Para reduzir a dimensionalidade dos dados de 8 para 2 dimens\u00f5es, utilizamos uma rede neural autoencoder. O autoencoder foi treinado para codificar os dados em um espa\u00e7o de 2 dimens\u00f5es e reconstrui-los a partir dessa codifica\u00e7\u00e3o. O objetivo \u00e9 preservar a estrutura e as rela\u00e7\u00f5es dos dados enquanto os projetamos para uma dimens\u00e3o mais baixa.\n", "\n", "A arquitetura do autoencoder \u00e9 composta por duas partes:\n", "- **Encoder:** que reduz a dimensionalidade dos dados de 8 para 2.\n", "- **Decoder:** que reconstr\u00f3i os dados de volta para 8 dimens\u00f5es.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### c) Objetivo: Visualiza\u00e7\u00e3o em 2D\n", "O objetivo principal \u00e9 transformar dados originalmente em 8 dimens\u00f5es em um novo espa\u00e7o bidimensional, de forma que a visualiza\u00e7\u00e3o dos dados em 2D facilite a an\u00e1lise. A redu\u00e7\u00e3o de dimensionalidade preserva a estrutura dos dados para que as classes possam ser separadas de forma clara.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### d) Apresenta\u00e7\u00e3o dos Dados no Novo Espa\u00e7o\n", "Ap\u00f3s o treinamento do autoencoder, projetamos os dados em 2 dimens\u00f5es e os visualizamos utilizando um gr\u00e1fico de dispers\u00e3o. O gr\u00e1fico resultante mostra as quatro classes de distribui\u00e7\u00f5es gaussianas, e as cores representam as diferentes classes $C_1$, $C_2$, $C_3$, $C_4$. As classes s\u00e3o visualmente separ\u00e1veis, o que confirma que o autoencoder conseguiu reduzir com sucesso a dimensionalidade preservando as rela\u00e7\u00f5es entre as distribui\u00e7\u00f5es."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "import torch.nn as nn\n", "import torch.optim as optim\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "\n", "# Reprodutibilidade\n", "np.random.seed(42)\n", "torch.manual_seed(42)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# M\u00e9dias das distribui\u00e7\u00f5es gaussianas\n", "means = [\n", "    np.array([0, 0, 0, 0, 0, 0, 0, 0]),\n", "    np.array([4, 0, 0, 0, 0, 0, 0, 0]),\n", "    np.array([0, 0, 4, 0, 0, 0, 0, 0]),\n", "    np.array([0, 0, 0, 0, 0, 0, 0, 4])\n", "]\n", "\n", "num_samples_per_class = 500\n", "X, y = [], []\n", "\n", "# Gerar amostras com vari\u00e2ncia unit\u00e1ria\n", "for i, mean in enumerate(means):\n", "    cov = np.eye(8)\n", "    samples = np.random.multivariate_normal(mean, cov, num_samples_per_class)\n", "    X.append(samples)\n", "    y.append(np.full(num_samples_per_class, i))\n", "\n", "X = np.vstack(X)\n", "y = np.concatenate(y)\n", "X_tensor = torch.tensor(X, dtype=torch.float32)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Autoencoder(nn.Module):\n", "    def __init__(self):\n", "        super(Autoencoder, self).__init__()\n", "        self.encoder = nn.Sequential(\n", "            nn.Linear(8, 4),\n", "            nn.ReLU(),\n", "            nn.Linear(4, 2)\n", "        )\n", "        self.decoder = nn.Sequential(\n", "            nn.Linear(2, 4),\n", "            nn.ReLU(),\n", "            nn.Linear(4, 8)\n", "        )\n", "\n", "    def forward(self, x):\n", "        z = self.encoder(x)\n", "        x_recon = self.decoder(z)\n", "        return x_recon\n", "\n", "# Instanciar modelo\n", "model = Autoencoder()\n", "criterion = nn.MSELoss()\n", "optimizer = optim.Adam(model.parameters(), lr=1e-3)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["epochs = 200\n", "for epoch in range(epochs):\n", "    optimizer.zero_grad()\n", "    outputs = model(X_tensor)\n", "    loss = criterion(outputs, X_tensor)\n", "    loss.backward()\n", "    optimizer.step()\n", "    \n", "    if (epoch + 1) % 20 == 0:\n", "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["with torch.no_grad():\n", "    encoded = model.encoder(X_tensor).numpy()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(8, 6))\n", "colors = ['red', 'green', 'blue', 'orange']\n", "labels = ['C1', 'C2', 'C3', 'C4']\n", "\n", "for i in range(4):\n", "    plt.scatter(encoded[y == i, 0], encoded[y == i, 1],\n", "                label=labels[i], alpha=0.6, color=colors[i])\n", "\n", "plt.title('Visualiza\u00e7\u00e3o 2D com Autoencoder')\n", "plt.xlabel('Dimens\u00e3o 1')\n", "plt.ylabel('Dimens\u00e3o 2')\n", "plt.legend()\n", "plt.grid(True)\n", "plt.tight_layout()\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 2}