{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/efrainmpp1/Neural-Network-PPGEEC2321/blob/main/Exercises_List_2/Q3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dY302cFtqvE3"
      },
      "source": [
        "# Visualização 2D com Autoencoder\n",
        "Neste notebook, vamos:\n",
        "1. Gerar 4 distribuições gaussianas de 8 dimensões com médias distintas.\n",
        "2. Treinar uma rede **autoencoder** para reduzir essas 8 dimensões para 2.\n",
        "3. Visualizar os dados codificados em 2D."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dxk4OSk6qvE7"
      },
      "source": [
        "### a) Definição das Distribuições Gaussianas\n",
        "O exercício começa com quatro distribuições gaussianas, cada uma com média diferente em um espaço de 8 dimensões. As médias dessas distribuições são:\n",
        "\n",
        "1. **Média de $C_1$:** $\\mathbf{m}_1 = (0, 0, 0, 0, 0, 0, 0, 0)$\n",
        "2. **Média de $C_2$:** $\\mathbf{m}_2 = (4, 0, 0, 0, 0, 0, 0, 0)$\n",
        "3. **Média de $C_3$:** $\\mathbf{m}_3 = (0, 0, 4, 0, 0, 0, 0, 0)$\n",
        "4. **Média de $C_4$:** $\\mathbf{m}_4 = (0, 0, 0, 0, 0, 0, 0, 4)$\n",
        "\n",
        "Cada distribuição tem variância unitária e suas amostras são geradas com base nessas médias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TATrhXDVqvE8"
      },
      "source": [
        "### b) Utilizando o Autoencoder para Visualização\n",
        "Para reduzir a dimensionalidade dos dados de 8 para 2 dimensões, utilizamos uma rede neural autoencoder. O autoencoder foi treinado para codificar os dados em um espaço de 2 dimensões e reconstrui-los a partir dessa codificação. O objetivo é preservar a estrutura e as relações dos dados enquanto os projetamos para uma dimensão mais baixa.\n",
        "\n",
        "A arquitetura do autoencoder é composta por duas partes:\n",
        "- **Encoder:** que reduz a dimensionalidade dos dados de 8 para 2.\n",
        "- **Decoder:** que reconstrói os dados de volta para 8 dimensões.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5JWgYAWqvFC"
      },
      "source": [
        "### c) Objetivo: Visualização em 2D\n",
        "O objetivo principal é transformar dados originalmente em 8 dimensões em um novo espaço bidimensional, de forma que a visualização dos dados em 2D facilite a análise. A redução de dimensionalidade preserva a estrutura dos dados para que as classes possam ser separadas de forma clara.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Gnj_DWPqvFC"
      },
      "source": [
        "### d) Apresentação dos Dados no Novo Espaço\n",
        "Após o treinamento do autoencoder, projetamos os dados em 2 dimensões e os visualizamos utilizando um gráfico de dispersão. O gráfico resultante mostra as quatro classes de distribuições gaussianas, e as cores representam as diferentes classes $C_1$, $C_2$, $C_3$, $C_4$. As classes são visualmente separáveis, o que confirma que o autoencoder conseguiu reduzir com sucesso a dimensionalidade preservando as relações entre as distribuições."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PBF-eW7qvFD",
        "outputId": "d4bee868-5f44-4b85-8b11-b8f3ea080ca7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7930ec9dcdb0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reprodutibilidade\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7gi3VN6qvFE"
      },
      "outputs": [],
      "source": [
        "# Médias das distribuições gaussianas\n",
        "means = [\n",
        "    np.array([0, 0, 0, 0, 0, 0, 0, 0]),\n",
        "    np.array([4, 0, 0, 0, 0, 0, 0, 0]),\n",
        "    np.array([0, 0, 4, 0, 0, 0, 0, 0]),\n",
        "    np.array([0, 0, 0, 0, 0, 0, 0, 4])\n",
        "]\n",
        "\n",
        "num_samples_per_class = 500\n",
        "X, y = [], []\n",
        "\n",
        "# Gerar amostras com variância unitária\n",
        "for i, mean in enumerate(means):\n",
        "    cov = np.eye(8)\n",
        "    samples = np.random.multivariate_normal(mean, cov, num_samples_per_class)\n",
        "    X.append(samples)\n",
        "    y.append(np.full(num_samples_per_class, i))\n",
        "\n",
        "X = np.vstack(X)\n",
        "y = np.concatenate(y)\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pALbYUkxqvFE"
      },
      "outputs": [],
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(8, 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4, 2)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(2, 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4, 8)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        x_recon = self.decoder(z)\n",
        "        return x_recon\n",
        "\n",
        "# Instanciar modelo\n",
        "model = Autoencoder()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NotVo44HqvFE"
      },
      "outputs": [],
      "source": [
        "epochs = 200\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_tensor)\n",
        "    loss = criterion(outputs, X_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wcma5SNrqvFF"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    encoded = model.encoder(X_tensor).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vN7Frca0qvFF"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "colors = ['red', 'green', 'blue', 'orange']\n",
        "labels = ['C1', 'C2', 'C3', 'C4']\n",
        "\n",
        "for i in range(4):\n",
        "    plt.scatter(encoded[y == i, 0], encoded[y == i, 1],\n",
        "                label=labels[i], alpha=0.6, color=colors[i])\n",
        "\n",
        "plt.title('Visualização 2D com Autoencoder')\n",
        "plt.xlabel('Dimensão 1')\n",
        "plt.ylabel('Dimensão 2')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}